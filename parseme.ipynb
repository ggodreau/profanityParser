{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Zerofucks:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.df = pd.DataFrame(\n",
    "            {'file': [], 'line_no': [], 'badword': [], 'content': []}, \n",
    "            columns=['file', 'line_no', 'badword', 'content']\n",
    "        )\n",
    "    \n",
    "    def __makeRegex__(self, shitToFind=[\"fuck\", \"shit\"]):\n",
    "        '''\n",
    "        shitToFind is a list of word literals,\n",
    "        uses word boundary \\b\n",
    "\n",
    "        returns a regex string\n",
    "        '''\n",
    "        shitString = ''\n",
    "        for word in shitToFind:\n",
    "            # shitString += r\"\\b\" + word + r\"\\b|\"\n",
    "            \n",
    "            # case insensitive (?i) has deprecation warning:\n",
    "            # https://github.com/bottlepy/bottle/issues/949\n",
    "            shitString += r\"(?i)\\b\" + word + r\"\\b|\"\n",
    "        return shitString[:-1]\n",
    "        \n",
    "    def write_df(self, path='./', filename='out.csv'):\n",
    "        '''\n",
    "        path: path to where you want to put the file\n",
    "        filename: name of file\n",
    "        \n",
    "        Writes the csv from self.df to a csv file\n",
    "        '''\n",
    "        try:\n",
    "            self.df.to_csv(path_or_buf=path + filename, index=False, chunksize=1000)\n",
    "            print(\"File written to {}\".format(path + filename))\n",
    "        except:\n",
    "            print(\"Unable to write csv, did you run .find_shit() yet?\")\n",
    "            \n",
    "    def erase_shit(self, input_file, output_file, bad_words=['fuck', 'shit']):\n",
    "        '''\n",
    "        Erases any bad words from the user specified files.\n",
    "        '''\n",
    "        \n",
    "        print('Replacing bad words in {}...'.format(input_file))\n",
    "#         try:\n",
    "        infile = open(input_file, mode='r').readlines()\n",
    "        outfile = open(output_file, mode='w')\n",
    "        shit_dict = {}\n",
    "        for content in tqdm(infile):\n",
    "            if len(re.findall(self.__makeRegex__(bad_words), content)) > 0:\n",
    "#                 print('Replacing {}...'.format(re.findall(self.__makeRegex__(bad_words), content)[0]))\n",
    "                if re.findall(self.__makeRegex__(bad_words), content)[0] in shit_dict:\n",
    "                    shit_dict[re.findall(self.__makeRegex__(bad_words), content)[0]] += 1\n",
    "                else:\n",
    "                    shit_dict[re.findall(self.__makeRegex__(bad_words), content)[0]] = 1\n",
    "            outfile.write(re.sub(self.__makeRegex__(bad_words), ' ', content))\n",
    "#         except:\n",
    "#             print('Unable to replace bad words in that file.')\n",
    "        return shit_dict\n",
    "    \n",
    "    def find_shit(self, root='./', bad_words=['fuck', 'shit']):\n",
    "        '''\n",
    "        root: the directory root where you want the crawl to start\n",
    "        bad_words: list of words you want to search for.\n",
    "            These can also be regular expressions. It will\n",
    "            match partials, so 'fuck' will match 'fucking',\n",
    "            'unfuckingbelievable', etc. Use \\b and similar\n",
    "            to constrain to word boundaries.\n",
    "        \n",
    "        The meat and potatoes, this is what conducts the walk\n",
    "        and writes the resultant dataframe to self.df.\n",
    "        \n",
    "        To export the df to a csv, use the write_df() method.\n",
    "        '''        \n",
    "        for item in os.walk(root):\n",
    "            \n",
    "            # keep records for each directory parsed\n",
    "            file_df = []\n",
    "            line_no_df = []\n",
    "            badword_df = []\n",
    "            content_df = []\n",
    "            \n",
    "            for file in item[2]:\n",
    "                print('Searching {}'.format(item[0]+'/'+file))\n",
    "                try:\n",
    "                    openfile = open(item[0] + '/' + file, \"r\").readlines()\n",
    "                    for line_no, content in enumerate(openfile):\n",
    "                        if len(re.findall(self.__makeRegex__(bad_words), content)) > 0:\n",
    "                            for i, badword in enumerate(re.findall(self.__makeRegex__(bad_words), content)):\n",
    "                                file_df.append(item[0]+'/'+file)\n",
    "                                line_no_df.append(line_no)\n",
    "                                badword_df.append(re.findall(self.__makeRegex__(bad_words),content)[i])\n",
    "                                # rstrip to remove newline character\n",
    "                                content_df.append(content.rstrip())\n",
    "                except:\n",
    "                    pass\n",
    "                            \n",
    "#             print(content_df)\n",
    "\n",
    "            # write the records to the dataframe with each dir parsed\n",
    "            self.df = self.df.append(pd.DataFrame({'file': file_df, \n",
    "                            'line_no': line_no_df, \n",
    "                            'badword': badword_df,\n",
    "                            'content': content_df},\n",
    "                            columns=['file', 'line_no', 'badword', 'content']),\n",
    "                            ignore_index=True)\n",
    "        \n",
    "        # change the silly auto-detected float line_no to an integer\n",
    "        self.df['line_no'] = self.df.copy()['line_no'].apply(lambda x: int(x))\n",
    "        # return self.df\n",
    "        print(\"Dataframe successfully created, \\n \\\n",
    "            use <obj>.df to print the df, or \\n \\\n",
    "            .write_df() method to write to file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find words in files\n",
    "\n",
    "Use this to find bad words in multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate class\n",
    "myFinder = Zerofucks()\n",
    "\n",
    "# load in bad words list from file,\n",
    "# write to list my_badwords\n",
    "my_badwords = []\n",
    "badwords_file = open('./bad_words.txt', \"r\").readlines()\n",
    "for line in badwords_file:\n",
    "    my_badwords.append(line.rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find stuff!\n",
    "myFinder.find_shit('./course_dump', my_badwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# myFinder.df.iloc[16,:].values\n",
    "myFinder.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myFinder.write_df(filename='output.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erase badwords from a file and return a 'cleaned' file\n",
    "\n",
    "Use this to erase badwords from a single file and return a cleaned file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/24138 [00:00<07:15, 55.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing bad words in ./labeledTrainData.tsv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24138/24138 [04:50<00:00, 83.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crap</th>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hell</th>\n",
       "      <td>521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>God</th>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gun</th>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>god</th>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drug</th>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>damn</th>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bloody</th>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count\n",
       "sex       783\n",
       "crap      606\n",
       "hell      521\n",
       "God       440\n",
       "dog       322\n",
       "gun       314\n",
       "god       223\n",
       "drug      215\n",
       "damn      186\n",
       "bloody    172"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# erase stuff! (returns a dictionary)\n",
    "out_dict = myFinder.erase_shit('./labeledTrainData.tsv', './out.tsv', my_badwords)\n",
    "# let's get a report of the stuff we replaced in the erase_shit() call:\n",
    "out_df = pd.DataFrame.from_dict(out_dict, orient='index')\n",
    "out_df.columns = ['count']\n",
    "out_df.sort_values('count', ascending=False)[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
